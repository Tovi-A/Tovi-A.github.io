---
title: Fast R-CNN
date: 2019-05-12 15:21:55
tags:
- 深度学习
- 论文阅读
categories: 论文阅读
comments: true
mathjax: true
---

# 摘要

本文提出了一种基于快速区域的卷积网络方法（Fast R-CNN）用于目标检测。Fast R-CNN建立在先前的工作基础上，以使用深度卷积网络有效地对对象提取进行分类。与之前的工作相比，Fast R-CNN采用了多项创新来提高训练和测试速度，同时提高了检测精度。Fast R-CNN训练非常深的VGG16网络比R-CNN快9倍，在测试时间快213倍，并在PASCAL VOC 2012上实现更高的mAP。与SPPnet相比，Fast R-CNN训练VGG16 3倍速更快，测试速度快10倍，并且更准确。快速R-CNN在Python和C ++中实现（使用Caffe），可通过https：//github.com/rbgirshick/fast-rcnn的开源MIT许可证获得。

# 1. 介绍

最近，深度ConvNets [14,16]显着改善了图像分类[14]和物体检测[9,19]的准确性。与图像分类相比，对象检测是一项更具挑战性的任务，需要更复杂的方法来解决。由于这种复杂性，当前的方法（例如，[9,11,19,25]）训练缓慢且不优雅的多级管道中的模型。
复杂性的产生是因为检测需要对象的准确定位，从而产生两个主要挑战。首先，必须处理许多候选对象位置（通常称为“提取”）。其次，这些候选者仅提供粗略的本地化，必须对其进行细化以实现精确定位。解决这些问题往往会影响速度，准确性或简单性。
在本文中，我们简化了最先进的基于ConvNet的物体探测器的训练过程[9,11]。我们提出了一种单阶段训练算法，该算法共同学习对对象提取进行分类并改进其空间位置。
由此产生的方法可以训练一个非常深的检测网络（VGG16 [20]）比R-CNN [9]快9倍，比SPPnet [11]快3倍。在运行时，检测网络以0.3s处理图像（不包括对象提取时间）当实现PASCAL VOC 2012 [7]的最高精度，mAP为66％（R-CNN为62％）.

## 1.1 R-CNN and SPPnet

基于区域的卷积网络方法（R-CNN）[9]通过使用深度ConvNet对对象提取进行分类，实现了出色的对象检测精度。然而，R-CNN有明显的缺点：<br>1. **训练是一个多阶段的管道。** R-CNN首先使用对数损失函数对对象提取进行ConvNet微调。然后，调整SVM到ConvNet功能。这些SVM充当对象检测器，取代了通过微调学习的softmax分类器。在第三个训练阶段，学习边界框回归量。<br>2. **训练在空间和时间上都很昂贵，代价很大。**对于SVM和边界框回归训练，从每个图像中的每个对象提取中提取特征并将其写入磁盘。对于非常深的网络，例如VGG16，这个过程需要一天2.5个GPU才能获得VOC07 trainval set的5k张图像。这些功能需要数百GB的存储空间。<br>3. **对象检测很慢。**在测试时，从每个测试图像中的每个对象提议中提取特征。使用VGG16进行检测需要47秒/图像（在GPU上）。<br>R-CNN很慢，因为它为每个对象提取执行ConvNet前向传递，而不共享计算。提出空间金字塔池化网络（SPPnets）[11]通过共享计算来加速R-CNN。 SPPnet方法计算整个输入图像的卷积特征映射，然后使用从共享特征映射中提取的特征向量对每个对象提取进行分类。通过将提取内部的特征地图的部分最大化为固定大小的输出（例如，6×6）来提取特征以用于提取。汇总多个输出大小，然后在空间金字塔池中连接[15]。 SPPnet在测试时将R-CNN加速10到100倍。由于更快的提案特征提取，训练时间也减少了3倍。<br>SPPnet也有明显的缺点。与R-CNN一样，训练是一个多阶段管道，涉及提取特征，用对数损失函数微调网络，训练SVM，最后拟合边界框回归。特征也写入磁盘。但与R-CNN不同，[11]中提出的微调算法无法更新空间金字塔层之前的卷积层。不出所料，这种限制（固定卷积层）限制了非常深的网络的准确性。

## 1.2 Contributions

我们提出了一种新的训练算法，它可以修复R-CNN和SPPnet的缺点，同时提高它们的速度和准确性。我们称这种方法为Fast R-CNN，因为它训练和测试的速度相对较快。快速R-CNN方法有几个优点：

a. 比R-CNN,SPPnet更高的检测质量(mAP)<br>b. 训练是单阶段的，使用多任务损失<br>c. 训练可以更新所有的网络层<br>d. 没有磁盘存储<br>Fast R-CNN是用Python和C++编写的（Caffe [13]），可以通过https://github.com/rbgirshick/fast-rcnn的开源MIT许可证获得。

# 2. Fast R-CNN architecture and training

![2019-05-12 18-41-29 的屏幕截图](./Fast-R-CNN/2019-05-12 18-41-29 的屏幕截图.png)

图1说明了Fast R-CNN架构。Fast R-CNN网络将整个图像和一组对象提取作为输入。网络首先使用几个卷积（conv）和最大池化层处理整个图像，以产生转换特征图。然后，对于每个对象提取，感兴趣区域（RoI）汇集层从特征映射中提取固定长度的特征向量。每个特征向量被馈送到一系列完全连接的（fc）层，最终分支成两个兄弟输出层：一个产生对K类对象类的softmax概率估计加上一个全能“背景”类和另一个输出层每个K对象类的四个实数值。每组4个值对K类之一的精细边界框位置进行编码。

## 2.1 The RoI pooling layer

RoI池化层使用最大池来将任何有效感兴趣区域内的特征转换为具有固定空间范围H×W（例如，7×7）的小特征映射，其中H和W是层超参数。独立于任何特定的RoI。在本文中，RoI是一个转换特征映射的矩形窗口。每个RoI由四元组$$(r，c，h，w)$$定义，指定其左上角$$(r, c)$$及其高度和宽度$(h, w)$。<br>RoI max pooling通过将$(h*w)$ RoI窗口划分为大约$(h/H * w/W)$的子窗口的$(H*W)$网格，然后将每个子窗口中的值最大汇集到相应的输出网格单元中来工作。池化独立应用于每个要素图通道，如标准最大池中所示。 RoI层只是SPPnets [11]中使用的空间金字塔池层的特例，其中只有一个金字塔层。我们使用[11]中给出的池子窗口计算。

## 2.2 Initializing from pre-trained networks

我们试验了三个预先训练过的ImageNet [4]网络，每个网络有五个最大池化层和五到十三个卷积层（参见4.1节网络细节）。当预训练的网络初始化Fast R-CNN网络时，它经历三次转换。<br>首先，最后一个最大池化层由RoI池化层替换，该池化层通过将H和W设置为与网络的第一个完全连接层相兼容来配置（例如，对于VGG16，H = W = 7）。
其次，网络的最后一个完全连接层和softmax（用于1000路ImageNet分类的训练）被前面描述的两个兄弟层替换（完全连接层和softmax over K + 1类别和类别特定的边界框回归量）。
第三，修改网络以获取两个数据输入：图像列表和那些图像中的RoI列表。

## 2.3 Fine-tuning for detection

使用反向传播训练所有网络权重是Fast R-CNN的重要功能。首先，让我们阐明为什么SPPnet无法更新空间金字塔池层下的权重。
根本原因是当每个训练样本（即RoI）来自不同的图像时，通过SPP层的反向传播非常低效，这正是R-CNN和SPPnet网络的训练方式。效率低下的原因在于每个RoI可能具有非常大的感受野，通常跨越整个输入图像。由于前向传播必须处理整个感受野，因此训练输入很大（通常是整个图像）。<br>我们提出了一种更有效的训练方法，利用训练期间的特征共享。在Fast R-CNN训练中，随机梯度下降（SGD）小批量分层采样，首先采样N个图像，然后通过从每个图像采样R / N RoI。重要的是，来自相同图像的RoI在前向和后向传递中共享计算和存储器。使N小减少小批量计算。例如，当使用N = 2且R = 128时，所提出的训练方案比从128个不同图像采样一个RoI（即，R-CNN和SPPnet策略）快大约64倍。<br>对该策略的一个担忧是它可能导致缓慢的训练收敛，因为来自相同图像的RoI是相关的。这个问题似乎不是一个实际问题，我们使用比R-CNN更少的SGD迭代，使用N = 2和R = 128获得了良好的结果。
除了分层采样之外，Fast R-CNN还使用简化的训练过程和一个微调阶段，共同优化softmax分类器和边界框重建器，而不是在三个不同的阶段训练softmax分类器，SVM和回归器[9,11]。该过程的组件（损失，小批量采样策略，通过RoI池化层的反向传播和SGD超参数）如下所述。<br>a. **Multi-task loss**. Fast R-CNN网络具有两个兄弟输出层。第一个输出离散概率分布（每个RoI），$$p =（p_0，...，p_K）$$，超过K + 1个类别。通常，p由完全连接层的K + 1输出上的softmax计算。第二个兄弟层为每个K个对象类输出边界框回归偏移$t^k = (t^k _x，t^k _y，t^k _w，t^k _h)$，由k索引。我们使用[9]中给出的$t^k$的参数化，其中$$t^k$$指定相对于对象提取的尺度不变的平移和对数空间高度/宽度转换。
每个训练RoI都标有地面实况类u和地面真实边界框回归目标v。我们在每个标记的RoI上使用多任务损失L来联合训练分类和边界框回归：<br>          $L(p,u,t^u,v)= L_{cls}(p,u)+λ[u≥1]L_{loc}(t^u,v)$，（1）<br>其中$L_{cls}(p,u)= -log p_u$是对数损失。<br>第二个任务丢失$L_{loc}$是在类u的真实边界框回归目标元组上定义的，$v=(v_x，v_y，v_w，v_h)$和预测的元组$t^u =(t^u _x，t^u _y，t^u _w ，t^u _h)$，再次对类u。当u≥1时，[u≥1]评估为1，否则为0。按照惯例，全能背景类被标记为u = 0.对于背景RoI，没有地面真相的概念边界框，因此$L_{loc}$被忽略。对于边界框回归，我们使用损失<br>            ![2019-05-13 10-36-17 的屏幕截图](./Fast-R-CNN/2019-05-13 10-36-17 的屏幕截图.png)

是一种强大的L1损耗，对R-CNN和SPPnet中使用的L2损耗的异常值不太敏感。当回归目标无限制时，L2损失训练可能需要仔细调整学习速率以防止梯度爆炸。Eq.3消除了这种敏感性。
Eq.1中的超参数λ控制两个任务损失之间的平衡。我们将地面实况回归目标$v_i$标准化为零均值和单位方差。所有实验都使用$λ = 1$。
我们注意到[6]使用相关损失来训练与类无关的对象提取网络。与我们的方法不同，[6]提出了一种将本地化和分类分开的双网络系统。 OverFeat [19]，R-CNN [9]和SPPnet [11]也训练分类器和边界框定位器，但是这些方法使用阶段式训练，我们表明它对于Fast R-CNN来说是次优的（第5.1节）。<br>b. **Mini-batch sampling.**在微调期间，每个SGD小批量由N = 2个图像构成，随机均匀选择（通常的做法是，我们实际上迭代数据集的排列）。我们使用尺寸为R = 128的小批量，从每个图像中采样64个RoI。与[9]中一样，我们从具有交叉联合（IoU）重叠的对象提取中获取25％的RoI与至少0.5的地面实例边界框重叠。这些RoI包括用前景对象类标记的示例，即u≥1。剩余的RoI是从对象提议中采样的，在[11,0]之后的区间[0.1,0.5]中具有最大IoU与地面实况。这些是背景示例，并标有u = 0. 0.1的下限阈值似乎充当了硬实例挖掘的启发式算法[8]。在训练期间，图像以0.5的概率水平翻转。没有使用其他数据扩充。<br>c. **Back-propagation through RoI pooling layers**.反向传播通过RoI池化层路由衍生物。为清楚起见，我们假设每个小批量只有一个图像（N = 1），尽管N>1的扩展是直截了当的，因为前向传递独立地处理所有图像。
令$x_i∈R$是进入RoI池化层的第i个激活输入，并且让$y_{rj}$成为来自第r个RoI的层的第j个输出。 RoI池化层计算$y_{rj} = x_{i *（r，j）}$，其中$i *（r，j）=argmax_{i^`∈R（r，j）}x_{i^`}$。 $R（r，j）$是子窗口中输入的索引集，输出单元$y_{rj}$ 在该子窗口中汇集。可以将单个$x_i$分配给几个不同的输出$y_{rj}$。
RoI池化层的向后函数通过遵循argmax开关计算损失函数相对于每个输入变量xi的偏导数：<br>              ![2019-05-13 17-39-08 的屏幕截图](./Fast-R-CNN/2019-05-13 17-39-08 的屏幕截图.png)

换句话说，对于每个小批量RoI r和每个池化输出单元$y_{rj}$，如果i是通过最大合并为yrj选择的argmax，则累积偏导数∂L/∂yrj。在反向传播中，偏导数∂L/∂yrj已经由RoI汇集层顶部的层的向后函数计算。<br>c. **SGD hyper-parameters**.用于softmax分类和边界框回归的完全连接的层分别从零均值高斯分布初始化，标准偏差分别为0.01和0.001。偏差初始化为0.所有层使用权重的每层学习率为1，偏差为2，全局学习率为0.001。在训练VOC07或VOC12 trainval时，我们运行SGD进行30k小批量迭代，然后将学习率降低到0.0001，并进行另外10k次迭代训练。当我们在更大的数据集上训练时，我们运行SGD以进行更多迭代，如稍后所述。使用0.9的动量和0.0005的参数衰减（基于重量和偏差）。

## 2.4 Scale invariance

我们探索了实现尺度不变对象检测的两种方法：（1）通过“强力”学习和（2）使用图像金字塔。这些策略遵循[11]中的两种方法。在蛮力方法中，在训练和测试期间以预定义的像素大小处理每个图像。网络必须直接从训练数据中学习尺度不变的物体检测。
相反，多尺度方法通过图像金字塔为网络提供近似的尺度不变性。在测试时，图像金字塔用于近似地对每个对象提取进行缩放标准化。在多尺度训练期间，我们在每次采样图像后随机采样金字塔尺度，[11]，作为数据增强的一种形式。由于GPU内存限制，我们仅尝试针对较小网络的多规模培训。

# 3. Fast R-CNN detection

一旦对Fast R-CNN网络进行微调，检测就会比运行正向传递更多（假设对象提取是预先计算的）。网络将图像（或图像金字塔，编码为图像列表）和R对象提议列表作为输入。在测试时间，R通常在2000左右，但我们会考虑它更大的情况（≈45k）。当使用图像金字塔时，每个RoI被分配给比例，使得缩放的RoI最接近区域中的$224^2$像素[11]。
对于每个测试RoI r，前向传递输出类后验概率分布p和一组相对于r的预测边界框偏移（每个K类获得其自己的精细边界框预测）。我们使用估计概率$P_r（class = k | r）=Δ p_k$为每个对象类k分配r的检测置信度。然后，我们使用R-CNN [9]的算法和设置，为每个类独立地执行非最大抑制。

## 3.1 Truncated SVD for faster detection

对于全图像分类，与conv层相比，计算完全连接层所花费的时间较少。相反，为了检测，要处理的RoI的数量很大，并且将近一半的正向传播时间用于计算完全连接的层（参见图2）。通过截断的SVD压缩它们可以很容易地加速大的完全连接层[5,23]。
在该技术中，由u×v权重矩阵W参数化的层近似地分解为<br>                 ![2019-05-13 18-11-22 的屏幕截图](./Fast-R-CNN/2019-05-13 18-11-22 的屏幕截图.png)

使用SVD。在该因式分解中，U是包含W的前t个左奇异向量的au×t矩阵，Σt是包含W的前t个奇异值的×t对角矩阵，并且V是包含第一个t右的v×t矩阵 - W的奇异向量。截断的SVD将参数计数从uv减少到t（u + v），如果t远小于min（u，v），则可能是显着的。为了压缩网络，对应于W的单个完全连接层被两个完全连接的层代替，它们之间没有非线性。这些层中的第一层使用权重矩阵ΣtVT（并且没有偏差），第二层使用U（原始双向与W相关联）。当RoI数量很大时，这种简单的压缩方法可以提供良好的加速。

# 6. Conclusion

本文提出了Fast R-CNN，一种干净，快速的R-CNN和SPPnet更新。 除了报告最先进的检测结果外，我们还提供了详细的实验，希望能够提供新的见解。特别值得注意的是，稀疏对象提取似乎可以提高检测器质量。 这个问题在过去进行探测时成本太高（及时），但对于Fast R-CNN变得切实可行。当然，可能存在尚未发现的技术，这些技术允许密集的框执行以及稀疏的提议。如果开发出这样的方法，可以帮助进一步加速物体检测。